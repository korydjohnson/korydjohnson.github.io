<html>
  <head>
    <title>Kory D. Johnson</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="style.css" />
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68809205-1', 'auto');
  ga('send', 'pageview');

</script>
  </head>
  <body>
    <div id="main", style="width: 650px; margin: auto;">
      <img width="270px" src="KoryJohnson.jpg" style="float: left; padding-right: 15px"> 
       <h1 style="margin-top: 0px"> Kory Johnson</h1> 
	  <!--<p> Ph.D. Candidate<br />
           <a href="https://statistics.wharton.upenn.edu/", target = "_blank">
		Statistics Department</a>, The Wharton School, University of Pennsylvania
          </p>-->
      <p><small>
	Vienna University of Economics and Business <br />
	Institute for Statistics and Mathematics <br />
	Welthandelsplatz 1, Room D4.4.124 <br />
	1020 Vienna, Austria <br />
	<br />
	kory.johnsontricam@wuhex.ac.at<br />
	(remove all climbing gear from the e-mail address or see CV)<br />
	<a href="CV.pdf", target="_blank"> Curriculum Vitae </a>
      </small></p></br></br></br>

 	  <h2> Background </h2>
	  <p> I am a Postdoctoral Research Fellow in the Institute for Statistics and Mathematics
		at the Vienna University of Economics and Business. 
	I completed my PhD in statistics at  
	    <a href="https://statistics.wharton.upenn.edu/", target = "_blank"> 
		The Wharton School, University of Pennsylvania</a> and was co-advised by
	    <a href="http://www-stat.wharton.upenn.edu/~stine/", target = "_blank">Robert Stine</a> and 
	    <a href="http://gosset.wharton.upenn.edu/~foster/index.pl", target = "_blank">Dean Foster</a>. </p>

	<p> My research is motivated by transparent machine learning methods. This includes 
		valid and computationally efficient versions of forward stepwise regression, 
		post-processing methods to correct the estimates of any algorithm to ensure 
		fairness, and valid prediction intervals for ``black-box'' models such as deep 
		neural networks and random forests. My work on forward stepwise allows one to 
		search complex interaction spaces while controlling for false rejections. There
		is a publicly available R package that can be used to fit these models:
		<a href="https://github.com/korydjohnson/rai", target="_blank">rai</a>.
		Fairness aware data mining (<a href="http://www.fatml.org/", target="_blank">FATML</a>)
		considers the reverse problem to 
		feature selection: the discrete removal of the influence of a covariate. Merely 
		excluding a covariate such as race does not necessarily remove its influence due 
		to its relationship with other covariates. My work effectively separates 
		prediction and fairness goals, allowing modelers to focus on generating highly 
		predictive models without incorporating the constraint of fairness. Lastly, the 
		prediction intervals are distribution-free, in that they only require 
		independent and identically distributed data. Their construction 
		is transparent enough that their use should become standard practice, much like 
		reporting standard errors along with mean estimates. </p>

	<p> Note that my CV (above) is kept more up-to-date than this site.</p>
	  
	  <h2> Education </h2> 
	  <p> PhD Statistics, The Wharton School, University of Pennsylvania, 2016. </p>
	  <p> MA Statistics, The Wharton School, University of Pennsylvania, 2016. </p>
	  <p> BS Economics-Concentration in Statistics, The Wharton School, University of Pennsylvania, 2011. </p> 
	  <p> BA Economics and Philosophy, College of Arts and Sciences, University of Pennsylvania, 2011. </p> 
	  
	  <h2> Papers </h2> 
	<ul style="width: 620px"> 

	<li> <u> <a href="https://arxiv.org/abs/1905.10634", target="_blank">
		Adaptive, distribution-free prediction intervals for deep neural networks.</a></u></u><br />
		Danijel Kivaranovic, Kory D Johnson, and Hannes Leeb. <br />
    	       <i>Submitted.</i></li>
	</br>

	<li> <u> Sequential Testing for Inference During Model Selection: Valid Stepwise Regression.</u></u><br />
		Johnson, K. D., Brown, L. D., Foster, D. P., and Stine, R. A. <br />
    	       <i>In Preparation.</i></li>
	</br>
	  <li> <u> <a href="http://arxiv.org/abs/1608.00528", target = "_blank"> 
		Impartial Predictive Modeling: Ensuring Fairness in Arbitrary Models.</a></u></u><br />
		Johnson, K. D., Foster, D. P., and Stine, R. A. <br />
	</br>
	  <li> <u> Commentary on Exact Post-selection Inference for Sequential Regression Procedures.</a></u></u><br />
		Lawrence D. Brown and Kory D. Johnson <br />
		   <i>Journal of the American Statistical Association.</i> Accepted, to appear.</li>
	</br>
	  <li> <u> <a href="http://arxiv.org/abs/1510.06301", target = "_blank"> Submodularity in Statistics: Comparing the Success of Model Selection Methods.</a></u></u><br />
		Johnson, K. D., Foster, D. P., and Stine, R. A. <br />
	</br>
	  <li> <u> <a href="http://arxiv.org/abs/1510.06322", target = "_blank"> Revisiting Alpha-Investing: Conditionally Valid Stepwise Regression.</a></u></u><br />
		Johnson, K. D., Foster, D. P., and Stine, R. A. <br />
	</br>
	  <li> <u> <a href="http://arxiv.org/abs/1510.06319", target = "_blank"> A Risk Ratio Comparison of l0 and l1 Penalized Regression.</a></u></u><br />
		Johnson, K. D., Foster, D. P., Lin, D., Stine, R. A., and Ungar, L. H. <br />
	</br>
	  <li> <u> <a href="techReport_reproductionNumber.pdf", target="_blank"> Estimating the reproduction number in the presence of superspreading.</a></u></u><br />
		K. Johnson, M. Beiglböck, M. Eder, A. Grass, J. Hermisson, G. Pammer, J. Polechova, D. Toneian, B. Wölfl<br />
    	       <i>In Preparation.</i></li>
	</ul> 
	 
          <!--<h2 id="software"> Software </h2>
<p> <a href="http://cran.r-project.org/web/packages/ivmodel/index.html">rai</a>: Implementation of the Revisiting Alpha-Investing (RAI) algorithm for feature selection. RAI provides a fast, scalable approximation to stepwise regression that is guaranteed to control the marginal false discovery rate.</p> -->
 
	  <h2> Teaching </h2>

	  <h4> Instructor: Lecturer </h4>
		<p> Winter 2018: Statistical Programming: Introduction to R  </p>
		<p> Summer 2018: Large-Scale Inference (master's level)  </p>
		<p> Winter 2017: Data Science Case Studies in R (master's level)  </p>
		<p> Summer 2017: Nonparametric Inference (master's level)  </p>
		<p> Summer 2015: Introductory Business Statistics  </p>

	  <h4> Instructor: Exercise Course </h4>
		<p> Summer 2017: Statistical Inference  </p>
		<p> Winter 2016: Linear Models  </p>
		<p> Spring 2015: Introductory Statistics  </p>
		<p> Spring 2012: Introductory Statistics </p>

	  <h4> Teaching Assistant </h4> 
		<p> Spring 2016: Modern Regression for the Social, Behavioral, and Biological Sciences</p>
		<p> Fall 2015: Introductory Business Statistics II</p>
		<p> Fall 2014: Introductory Business Statistics I </p>
		<p> Spring 2014: Applied Econometrics II </p>
		<p> Fall 2013: Intermediate Statistics</p>
		<p> Spring 2013: Introductory Business Statistics I</p>
		<p> Fall 2012: Applied Econometrics I</p>
		<p> Fall 2011: Introductory Business Statistics II</p>

	  <h2> Honors and Awards </h2>
		<p> <i> SIAM Student Travel Award</i>, 2014. SIAM International Conference on Data Mining. <br />
        	</p>
		<p> <i> Elected to Phi Beta Kappa</i>, 2011. University of Pennsylvania.<br />
        	</p>

	  <h2> Personal </h2> 
	 	<p> My non-academic hobbies are rock climbing, splitboarding, and mountaineering. 
			For highlights from recent trips, click 
		    <a href="https://instagram.com/korydjohnson/", target = "_blank">here</a>. 
    </div>
  </body>
</html>

